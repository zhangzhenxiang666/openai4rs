# openai4rs

[![Crates.io](https://img.shields.io/crates/v/openai4rs)](https://crates.io/crates/openai4rs)
[![Documentation](https://docs.rs/openai4rs/badge.svg)](https://docs.rs/openai4rs)
[![License](https://img.shields.io/crates/l/openai4rs)](LICENSE)

ç®€ä½“ä¸­æ–‡ | [English](README_en.md)

ä¸€ä¸ªåŸºäº `tokio` å’Œ `reqwest` çš„å¼‚æ­¥ Rust crateï¼Œç”¨äºä¸éµå¾ª OpenAI è§„èŒƒçš„å¤§æ¨¡å‹ä¾›åº”å•†è¿›è¡Œäº¤äº’ã€‚

## âœ¨ ç‰¹æ€§

### ğŸ—¨ï¸ Chat èŠå¤©

- âœ… æµå¼å“åº”
- âœ… å·¥å…·è°ƒç”¨
- âœ… æ€è€ƒæ¨¡å¼

### ğŸ“ Completions æ–‡æœ¬è¡¥å…¨

- âœ… éæµå¼å“åº”
- âœ… æµå¼å“åº”

### ğŸ¤– Models æ¨¡å‹ç®¡ç†

- âœ… è·å–æ¨¡å‹åˆ—è¡¨
- âœ… è·å–å•ä¸ªæ¨¡å‹ä¿¡æ¯

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

æ·»åŠ ä¾èµ–åˆ°ä½ çš„ `Cargo.toml`ï¼š

```toml
[dependencies]
openai4rs = "0.1.3"
tokio = { version = "1.45.1", features = ["full"] }
futures = "0.3.31"
```

æˆ–ä½¿ç”¨ cargo å‘½ä»¤ï¼š

```bash
cargo add openai4rs
```

### åŸºç¡€ä½¿ç”¨

```rust
use openai4rs::{OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("Hello, world!")];
    
    let response = client
        .chat()
        .create(chat_request("gpt-3.5-turbo", &messages))
        .await
        .unwrap();
        
    println!("{:#?}", response);
}
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### **ğŸ—¨ï¸ Chat èŠå¤©**

#### éæµå¼èŠå¤©

æœ€ç®€å•çš„èŠå¤©æ–¹å¼ï¼Œä¸€æ¬¡æ€§è·å–å®Œæ•´å“åº”ï¼š

```rust
use openai4rs::{OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")];
    
    let chat_completion = client
        .chat()
        .create(chat_request("your_model_name", &messages))
        .await
        .unwrap();
        
    println!("{:#?}", chat_completion);
}
```

#### æµå¼èŠå¤©

å®æ—¶æ¥æ”¶å“åº”å†…å®¹ï¼Œé€‚åˆéœ€è¦é€æ­¥æ˜¾ç¤ºçš„åœºæ™¯ï¼š

```rust
use futures::StreamExt;
use openai4rs::{OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è¯·å†™ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½çš„æ•…äº‹")];
    
    let mut stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();
        
    while let Some(result) = stream.next().await {
        let chunk = result.unwrap();
        // å¤„ç†æ¯ä¸ªå“åº”å—
        for choice in chunk.choices.iter() {
            if let Some(content) = &choice.delta.content {
                print!("{}", content);
            }
        }
    }
}
```

#### ğŸ”§ å·¥å…·è°ƒç”¨

è®©æ¨¡å‹èƒ½å¤Ÿè°ƒç”¨å¤–éƒ¨å·¥å…·æ¥å¢å¼ºåŠŸèƒ½ï¼š

```rust
use futures::StreamExt;
use openai4rs::{ChatCompletionToolParam, OpenAI, chat_request, user, ToolChoice};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    
    // å®šä¹‰å·¥å…·
    let tools = vec![ChatCompletionToolParam::function(
        "get_current_time",
        "è·å–å½“å‰æ—¶é—´",
        serde_json::json!({
            "type": "object",
            "properties": {},
            "description": "è·å–å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´"
        }),
    )];

    let messages = vec![user!("ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ")];
    
    let mut stream = client
        .chat()
        .create_stream(
            chat_request("your_model_name", &messages)
                .tools(tools)
                .tool_choice(ToolChoice::Auto)
        )
        .await
        .unwrap();
        
    while let Some(result) = stream.next().await {
        match result {
            Ok(chunk) => {
                println!("æ”¶åˆ°å“åº”: {:#?}", chunk);
            }
            Err(err) => {
                eprintln!("é”™è¯¯: {:#?}", err);
            }
        }
    }
}
```

#### ğŸ§  æ€è€ƒæ¨¡å¼

ä¾›åº”å•†è¿”å›å­—æ®µä¸ºreasoningæˆ–reasoning_contentéƒ½ä¼šæ˜ å°„åˆ°reasoningå­—æ®µã€‚
é€‚ç”¨äºæ”¯æŒæ€è€ƒåŠŸèƒ½çš„æ¨¡å‹ï¼ˆå¦‚ qwen çš„ qwq-32bï¼‰ï¼š

```rust
use futures::StreamExt;
use openai4rs::{OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è¯·è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜ï¼šå¦‚æœä¸€ä¸ªä¸‰è§’å½¢çš„ä¸¤è¾¹åˆ†åˆ«æ˜¯3å’Œ4ï¼Œç¬¬ä¸‰è¾¹æ˜¯5ï¼Œè¿™æ˜¯ä»€ä¹ˆç±»å‹çš„ä¸‰è§’å½¢ï¼Ÿ")];
    
    let mut stream = client
        .chat()
        .create_stream(chat_request("qwq-32b", &messages))
        .await
        .unwrap();
        
    while let Some(result) = stream.next().await {
        let chunk = result.unwrap();
        for choice in chunk.choices.iter() {
            // æ˜¾ç¤ºæ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹
            if choice.delta.is_reasoning() {
                println!("ğŸ¤” æ€è€ƒè¿‡ç¨‹:\n{}", choice.delta.get_reasoning_str());
            }
            // æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            if let Some(content) = &choice.delta.content {
                if !content.is_empty() {
                    println!("ğŸ’¡ å›ç­”:\n{}", content);
                }
            }
        }
    }
}
```

### ğŸ”„ æµå¤„ç†å·¥å…·

#### Apply - åŒæ­¥éå†

ä½¿ç”¨ `Apply` trait å¯ä»¥æ›´æ–¹ä¾¿åœ°å¤„ç†æµæ•°æ®ï¼š

```rust
use openai4rs::{Apply, OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è¯·ä»‹ç»ä¸€ä¸‹ Rust ç¼–ç¨‹è¯­è¨€")];

    let stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();

    // åŒæ­¥å¤„ç†æ¯ä¸ªå“åº”å—
    stream.apply(|result| {
        let chunk = result.unwrap();
        println!("å¤„ç†å“åº”å—: {:#?}", chunk);
    });
}
```

#### Apply - å¼‚æ­¥éå†

##### ç®€å•å¼‚æ­¥å¤„ç†

```rust
use openai4rs::{Apply, OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")];
    
    let stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();
        
    stream
        .apply_async(|result| async move {
            let chunk = result.unwrap();
            // å¯ä»¥åœ¨è¿™é‡Œæ‰§è¡Œå¼‚æ­¥æ“ä½œ
            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
            println!("å¼‚æ­¥å¤„ç†: {:#?}", chunk);
        })
        .await;
}
```

##### æ•è·å¤–éƒ¨çŠ¶æ€çš„å¼‚æ­¥å¤„ç†

```rust
use openai4rs::{Apply, OpenAI, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è¯·å†™ä¸€é¦–å…³äºç¼–ç¨‹çš„è¯—")];

    let stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();

    // æ”¶é›†å®Œæ•´çš„AIè¾“å‡º
    let complete_response = stream
        .apply_with_capture_async(String::new(), |accumulated, result| {
            Box::pin(async move {
                let chunk = result.expect("å¤„ç†æµæ—¶å‡ºé”™");
                for choice in chunk.choices.iter() {
                    if let Some(content) = choice.delta.content.as_ref() {
                        print!("{}", content); // å®æ—¶æ˜¾ç¤º
                        accumulated.push_str(content); // ç´¯ç§¯å†…å®¹
                    }
                }
            })
        })
        .await;

    println!("\n\nå®Œæ•´å“åº”:\n{}", complete_response);
}
```

### ğŸ”— å“åº”åˆå¹¶ä¸æ¶ˆæ¯æ˜ å°„

#### åˆå¹¶æµå¼å“åº”è¾“å‡º(ä½¿ç”¨é‡è½½çš„ `+` è¿è¡Œç¬¦)

å°†æµå¼å“åº”åˆå¹¶ä¸ºå®Œæ•´çš„å›å¤å†…å®¹ï¼š

```rust
use futures::stream::StreamExt;
use openai4rs::{OpenAI, StreamChoice, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let messages = vec![user!("è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹ Rust çš„æ‰€æœ‰æƒæœºåˆ¶")];

    let mut stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();

    let mut merged_choice: Option<StreamChoice> = None;
    while let Some(result) = stream.next().await {
        let chat_completion_chunk = result.unwrap();
        let choice = chat_completion_chunk.choices[0].clone();
        merged_choice = Some(match merged_choice {
            Some(l) => l + choice,
            None => choice,
        })
    }
    println!("{:#?}", merged_choice.unwrap());
}
```

#### å°†å“åº”æ˜ å°„åˆ°æ¶ˆæ¯é“¾

```rust
use futures::stream::StreamExt;
use openai4rs::{OpenAI, StreamChoice, chat_request, user};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    let mut messages = vec![user!("è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹ Rust çš„æ‰€æœ‰æƒæœºåˆ¶")];

    let mut stream = client
        .chat()
        .create_stream(chat_request("your_model_name", &messages))
        .await
        .unwrap();

    let mut merged_choice: Option<StreamChoice> = None;
    while let Some(result) = stream.next().await {
        let chat_completion_chunk = result.unwrap();
        let choice = chat_completion_chunk.choices[0].clone();
        merged_choice = Some(match merged_choice {
            Some(l) => l + choice,
            None => choice,
        })
    }
    messages.push(merged_choice.unwrap().delta.into());

    messages.push(user!("å¥½çš„, è°¢è°¢ä½ "));

    let chat_completion = client
        .chat()
        .create(chat_request("your_model_name", &messages))
        .await
        .unwrap();

    messages.push(chat_completion.choices[0].message.clone().into())
}
```

### **ğŸ“ Completions æ–‡æœ¬è¡¥å…¨**

#### éæµå¼è¡¥å…¨

```rust
use openai4rs::{OpenAI, comletions_request};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    
    let completion = client
        .completions()
        .create(comletions_request("your_model_name", "è¯·è¡¥å…¨è¿™å¥è¯ï¼šäººå·¥æ™ºèƒ½çš„æœªæ¥"))
        .await
        .unwrap();
        
    println!("è¡¥å…¨ç»“æœ: {:#?}", completion);
}
```

#### æµå¼è¡¥å…¨

```rust
use futures::StreamExt;
use openai4rs::{OpenAI, comletions_request};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    
    let mut stream = client
        .completions()
        .create_stream(comletions_request("your_model_name", "ç¼–å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼š"))
        .await
        .unwrap();
        
    while let Some(result) = stream.next().await {
        match result {
            Ok(completion) => {
                println!("è¡¥å…¨å†…å®¹: {:#?}", completion);
            }
            Err(err) => {
                eprintln!("é”™è¯¯: {}", err);
            }
        }
    }
}
```

### **ğŸ¤– Models æ¨¡å‹ç®¡ç†**

#### è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹

```rust
use openai4rs::{OpenAI, models_request};

#[tokio::main]
async fn main() {
    let client = OpenAI::new("your_api_key", "your_base_url");
    
    let models = client
        .models()
        .list(models_request())
        .await
        .unwrap();
        
    println!("å¯ç”¨æ¨¡å‹:");
    for model in models.data.iter() {
        println!("- {}: {}", model.id, model.created);
    }
}
```

## ğŸ”§ é…ç½®é€‰é¡¹

### å®¢æˆ·ç«¯é…ç½®

```rust
use openai4rs::{OpenAI};

// åŸºç¡€é…ç½®
let client = OpenAI::new("your_api_key", "https://api.openai.com/v1");

```

### è¯·æ±‚å‚æ•°é…ç½®

```rust
use openai4rs::{chat_request, user};

let messages = vec![user!("Hello")];

let request = chat_request("gpt-3.5-turbo", &messages)
    .temperature(0.7)             // æ§åˆ¶éšæœºæ€§
    .max_completion_tokens(1000)  // æœ€å¤§tokenæ•°
    .top_p(0.9)                   // æ ¸å¿ƒé‡‡æ ·
    .frequency_penalty(0.1)       // é¢‘ç‡æƒ©ç½š
    .presence_penalty(0.1);       // å­˜åœ¨æƒ©ç½š
```

## ğŸ“– æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ [examples](examples/) ç›®å½•è·å–æ›´å¤šä½¿ç”¨ç¤ºä¾‹ï¼š

- [åŸºç¡€èŠå¤©](examples/chat.rs)
- [æµå¼å“åº”](examples/chat_stream.rs)
- [å·¥å…·è°ƒç”¨](examples/tool.rs)
- [æ€è€ƒæ¨¡å¼](examples/chat_reasoning_stream.rs)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache-2.0 è®¸å¯è¯](LICENSE)ã€‚

## ğŸ”— ç›¸å…³é“¾æ¥

- [æ–‡æ¡£](https://docs.rs/openai4rs)
- [Crates.io](https://crates.io/crates/openai4rs)
- [GitHub ä»“åº“](https://github.com/zhangzhenxiang666/openai4rs)
- [é—®é¢˜åé¦ˆ](https://github.com/zhangzhenxiang666/openai4rs/issues)
